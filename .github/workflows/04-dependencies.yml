# Workflow 04 : Gestion des Dépendances avec Cache
# Objectif : Optimiser l'installation des dépendances avec le cache

name: 04 - Dépendances et Cache

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  installation-avec-cache:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout du code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          # Cache automatique des dépendances pip
          cache: 'pip'
      
      # Créer un fichier requirements.txt pour l'exemple
      - name: Créer requirements.txt
        run: |
          cat > requirements.txt << 'EOF'
          numpy==1.24.3
          pandas==2.0.3
          scikit-learn==1.3.0
          matplotlib==3.7.2
          seaborn==0.12.2
          joblib==1.3.2
          EOF
      
      # Installation des dépendances (sera cachée)
      - name: Installer les dépendances
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      # Vérifier les installations
      - name: Vérifier les installations
        run: |
          pip list
          python -c "import numpy; print(f'NumPy version: {numpy.__version__}')"
          python -c "import pandas; print(f'Pandas version: {pandas.__version__}')"
          python -c "import sklearn; print(f'Scikit-learn version: {sklearn.__version__}')"
      
      # Créer un script simple de preprocessing
      - name: Script de preprocessing simple
        run: |
          python << 'EOF'
          import numpy as np
          import pandas as pd
          from sklearn.preprocessing import StandardScaler
          
          # Créer des données synthétiques
          print("Création de données synthétiques...")
          data = np.random.randn(100, 5)
          df = pd.DataFrame(data, columns=['feature1', 'feature2', 'feature3', 'feature4', 'feature5'])
          
          print(f"Shape: {df.shape}")
          print(f"Premières lignes:\n{df.head()}")
          
          # Normalisation
          scaler = StandardScaler()
          scaled_data = scaler.fit_transform(df)
          
          print(f"\nMoyennes après normalisation: {scaled_data.mean(axis=0)}")
          print(f"Écarts-types après normalisation: {scaled_data.std(axis=0)}")
          EOF